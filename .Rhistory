geom_col(fill = "#008E19") +
theme_minimal(base_size = 15) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_label(aes(label = sales_text)) +
scale_y_continuous(labels = scales::dollar_format(big.mark = ".",
decimal.mark = ",",
prefix = "",
suffix = " €")) +
labs(
title    = "Revenue by state",
x = "State",
y = "Revenue"
)
## Sales by State and Year - Visualize
plotti(loc_data = "sales_in_Baden-Württemberg",
loc_city = "Baden-Württemberg")
plotti(loc_data = "sales_in_Bavaria",
loc_city = "Bavaria")
plotti(loc_data = "sales_in_Berlin",
loc_city = "Berlin")
plotti(loc_data = "sales_in_Bremen",
loc_city = "Bremen")
plotti(loc_data = "sales_in_Hamburg",
loc_city = "Hamburg")
plotti(loc_data = "sales_in_Hesse",
loc_city = "Hesse")
plotti(loc_data = "sales_in_Lower Saxony",
loc_city = "Lower Saxony")
plotti(loc_data = "sales_in_Mecklenburg-Western Pomerania",
loc_city = "Mecklenburg-Western Pomerania")
plotti(loc_data = "sales_in_North Rhine-Westphalia",
loc_city = "North Rhine-Westphalia")
plotti(loc_data = "sales_in_Saxony",
loc_city = "Saxony")
plotti(loc_data = "sales_in_Saxony-Anhalt",
loc_city = "Saxony-Anhalt")
plotti(loc_data = "sales_in_Schleswig-Holstein",
loc_city = "Schleswig-Holstein")
library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(httr)
url <- "https://www.rosebikes.com/bikes"
html <- read_html(url)
bike_tbl <- html %>%
html_nodes(".catalog-navigation__link") %>%
html_attrs() %>%
bind_rows()  %>%
select(title, href) %>%
rename(family_url = href, bike_family = title) %>%
mutate(family_url = glue("https://www.rosebikes.com{family_url}")) %>%
filter(bike_family != "Sale")
read_categories <- function(nr){
bike_category_url <- bike_tbl$family_url[nr]
bike_category_html <- read_html(bike_category_url)
bike_category_names_tbl <- bike_category_html %>%
html_nodes(".catalog-category-bikes__title-text") %>%
html_text() %>%
stringr::str_extract("(?<=\\n).*(?=\\n)") %>%
as_tibble
bike_category_price_tbl <- bike_category_html %>%
html_nodes(".catalog-category-bikes__price-title") %>%
html_text() %>%
stringr::str_extract("(?<=from ).*(?=.00)") %>%
stringr::str_replace(pattern = ",", replacement = "") %>%
as_tibble
pricelist_map <- bind_cols(bike_tbl$bike_family[nr], bike_category_names_tbl, bike_category_price_tbl)
}
pricelist_tbl <- map(c(1:9),read_categories) %>%
bind_rows() %>% rename(Family = ...1, Category = value...2, Price = value...3)
pricelist_tbl[is.na(pricelist_tbl)] <- "Coming Soon"
slice(pricelist_tbl, c(1:10))
rm(list = ls())
# Data Science at TUHH ------------------------------------------------------
# SALES ANALYSIS ----
# 1.0 Load libraries ----
library(tidyverse)
library(readxl)
library(lubridate)
# 2.0 Importing Files ----
bikes_tbl <- read_excel("00_data/01_bike_sales/01_raw_data/bikes.xlsx")
bikeshops_tbl <- read_excel("00_data/01_bike_sales/01_raw_data/bikeshops.xlsx")
orderlines_tbl <- read_excel("00_data/01_bike_sales/01_raw_data/orderlines.xlsx")
# 4.0 Joining Data ----
bike_orderlines_joined_tbl <- orderlines_tbl %>%
left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>%
left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))
# 5.0 Wrangling Data
bike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%
# 5.1 Separate category name
separate(col    = category,
into   = c("category.1", "category.2", "category.3"),
sep    = " - ") %>%
# 5.2 Add the total price (price * quantity)
mutate(total.price = price * quantity) %>%
# 5.3 Reorganize
select(-...1, -gender) %>%
select(-ends_with(".id")) %>%
bind_cols(bike_orderlines_joined_tbl %>% select(order.id)) %>%
select(order.id, contains("order"), contains("model"), contains("category"),
price, quantity, total.price,
everything()) %>%
rename(bikeshop = name) %>%
set_names(names(.) %>% str_replace_all("\\.", "_"))
####### Challenge
##### Sales by State - Manipulate
sales_by_state_tbl <- bike_orderlines_wrangled_tbl %>%
separate(col = location,
into = c('city', 'state'),
sep = ', ',
convert = T) %>%
select(state, total_price) %>%
group_by(state)  %>%
summarize(sales = sum(total_price)) %>%
arrange(state) %>%
mutate(sales_text = scales::dollar(sales, big.mark = ".",
decimal.mark = ",",
prefix = "",
suffix = " €"))
#### Sales by State and Year - Manipulate
sales_by_state_and_year_tbl <- bike_orderlines_wrangled_tbl %>%
separate(col = location,
into = c('city', 'state'),
sep = ', ',
convert = T) %>%
mutate(year = year(order_date)) %>%
select(state, year, total_price) %>%
group_by(state, year)  %>%
summarize(sales = sum(total_price)) %>%
arrange(state, year) %>%
mutate(sales_text = scales::dollar(sales, big.mark = ".",
decimal.mark = ",",
prefix = "",
suffix = " €"))
for (jj in c(1:nrow(sales_by_state_tbl))) {
assign(
paste("sales_in_",
sales_by_state_tbl[jj,1],
sep = ''),
sales_by_state_and_year_tbl[sales_by_state_and_year_tbl$state == sales_by_state_tbl[[jj,1]],]
)
}
plotti <- function(loc_data, loc_city) {
eval(as.name(loc_data)) %>%
ggplot(aes(x = year, y = sales)) +
geom_col(fill = "#008E19") +
theme_minimal(base_size = 15) +
geom_label(aes(label = sales_text)) +
geom_smooth(method = "lm", se = FALSE) +
scale_y_continuous(labels =
scales::dollar_format(big.mark = ".",
decimal.mark = ",",
prefix = "",
suffix = " €")) +
labs(title = paste("Revenue by year in ",
loc_city, sep=""),
x = "Year",
y = "Revenue")
}
## Sales by State - Visualize
sales_by_state_tbl %>%
arrange(sales) %>%
mutate(state = factor(state, levels = state)) %>%
ggplot(aes(x = state, y = sales)) +
geom_col(fill = "#008E19") +
theme_minimal(base_size = 15) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_label(aes(label = sales_text)) +
scale_y_continuous(labels = scales::dollar_format(big.mark = ".",
decimal.mark = ",",
prefix = "",
suffix = " €")) +
labs(
title    = "Revenue by state",
x = "State",
y = "Revenue"
)
## Sales by State and Year - Visualize
plotti(loc_data = "sales_in_Baden-Württemberg",
loc_city = "Baden-Württemberg")
plotti(loc_data = "sales_in_Bavaria",
loc_city = "Bavaria")
plotti(loc_data = "sales_in_Berlin",
loc_city = "Berlin")
plotti(loc_data = "sales_in_Bremen",
loc_city = "Bremen")
plotti(loc_data = "sales_in_Hamburg",
loc_city = "Hamburg")
plotti(loc_data = "sales_in_Hesse",
loc_city = "Hesse")
plotti(loc_data = "sales_in_Lower Saxony",
loc_city = "Lower Saxony")
plotti(loc_data = "sales_in_Mecklenburg-Western Pomerania",
loc_city = "Mecklenburg-Western Pomerania")
plotti(loc_data = "sales_in_North Rhine-Westphalia",
loc_city = "North Rhine-Westphalia")
plotti(loc_data = "sales_in_Saxony",
loc_city = "Saxony")
plotti(loc_data = "sales_in_Saxony-Anhalt",
loc_city = "Saxony-Anhalt")
plotti(loc_data = "sales_in_Schleswig-Holstein",
loc_city = "Schleswig-Holstein")
library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(httr)
Read_API <-function(nr){
ram_api <- GET(glue("https://rickandmortyapi.com/api/character/?page={nr}"))
ram_loop <- ram_api   %>%
.$content  %>%
rawToChar()  %>%
fromJSON() %>%
purrr::pluck("results") %>% as_tibble
}
ram_character <- map(c(1:33),Read_API) %>%
bind_rows
ram_origin <- bind_cols(ram_character$origin) %>% select(name) %>% rename(origin = name)
ram_location <- bind_cols(ram_character$location) %>% select (name) %>% rename(current_location = name)
ram_character <- ram_character %>%
select(name, status, species, gender) %>%
add_column(ram_origin, ram_location) %>%
arrange(species, status, origin, current_location)
library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(httr)
url <- "https://www.rosebikes.com/bikes"
html <- read_html(url)
bike_tbl <- html %>%
html_nodes(".catalog-navigation__link") %>%
html_attrs() %>%
bind_rows()  %>%
select(title, href) %>%
rename(family_url = href, bike_family = title) %>%
mutate(family_url = glue("https://www.rosebikes.com{family_url}")) %>%
filter(bike_family != "Sale")
read_categories <- function(nr){
bike_category_url <- bike_tbl$family_url[nr]
bike_category_html <- read_html(bike_category_url)
bike_category_names_tbl <- bike_category_html %>%
html_nodes(".catalog-category-bikes__title-text") %>%
html_text() %>%
stringr::str_extract("(?<=\\n).*(?=\\n)") %>%
as_tibble
bike_category_price_tbl <- bike_category_html %>%
html_nodes(".catalog-category-bikes__price-title") %>%
html_text() %>%
stringr::str_extract("(?<=from ).*(?=.00)") %>%
stringr::str_replace(pattern = ",", replacement = "") %>%
as_tibble
pricelist_map <- bind_cols(bike_tbl$bike_family[nr], bike_category_names_tbl, bike_category_price_tbl)
}
pricelist_tbl <- map(c(1:9),read_categories) %>%
bind_rows() %>% rename(Family = ...1, Category = value...2, Price = value...3)
pricelist_tbl[is.na(pricelist_tbl)] <- "Coming Soon"
slice(pricelist_tbl, c(1:10))
rm(bike_orderlines_joined_tbl, bike_orderlines_wrangled_tbl, bike_tbl, bikes_tbl, bikeshop_tbl, html,
orderlines_tbl, pricelist_tbl, ram_character, ram_location, ram_origin, sales_by_state_and_year_tbl,
sales_by_state_tbl, `sales_in_Baden-Württemberg`, sales_in_Bavaria, sales_in_Berlin, sales_in_Bremen,
sales_in_Hamburg, sales_in_Hesse, `sales_in_Lower Saxony`, `sales_in_Mecklenburg-Western Pomerania`,
`sales_in_North Rhine-Westphalia`, sales_in_Saxony, `sales_in_Saxony-Anhalt`, `sales_in_Schleswig-Holstein`)
rm(bike_orderlines_joined_tbl, bike_orderlines_wrangled_tbl, bike_tbl, bikes_tbl, bikeshops_tbl, html,
orderlines_tbl, pricelist_tbl, ram_character, ram_location, ram_origin, sales_by_state_and_year_tbl,
sales_by_state_tbl, `sales_in_Baden-Württemberg`, sales_in_Bavaria, sales_in_Berlin, sales_in_Bremen,
sales_in_Hamburg, sales_in_Hesse, `sales_in_Lower Saxony`, `sales_in_Mecklenburg-Western Pomerania`,
`sales_in_North Rhine-Westphalia`, sales_in_Saxony, `sales_in_Saxony-Anhalt`, `sales_in_Schleswig-Holstein`,
)
rm(sales_in_Baden-Württemberg)
rm(`sales_in_Baden-Württemberg`)
rm(bike_orderlines_joined_tbl, bike_orderlines_wrangled_tbl, bike_tbl, bikes_tbl, bikeshops_tbl, html,
orderlines_tbl, pricelist_tbl, ram_character, ram_location, ram_origin, sales_by_state_and_year_tbl,
sales_by_state_tbl, `sales_in_Baden-Württemberg`, sales_in_Bavaria, sales_in_Berlin, sales_in_Bremen,
sales_in_Hamburg, sales_in_Hesse, `sales_in_Lower Saxony`, `sales_in_Mecklenburg-Western Pomerania`,
`sales_in_North Rhine-Westphalia`, sales_in_Saxony, `sales_in_Saxony-Anhalt`, `sales_in_Schleswig-Holstein`,
jj, url, plotti, READ_API, read_categories)
rm(bike_orderlines_joined_tbl, bike_orderlines_wrangled_tbl, bike_tbl, bikes_tbl, bikeshops_tbl, html,
orderlines_tbl, pricelist_tbl, ram_character, ram_location, ram_origin, sales_by_state_and_year_tbl,
sales_by_state_tbl, `sales_in_Baden-Württemberg`, sales_in_Bavaria, sales_in_Berlin, sales_in_Bremen,
sales_in_Hamburg, sales_in_Hesse, `sales_in_Lower Saxony`, `sales_in_Mecklenburg-Western Pomerania`,
`sales_in_North Rhine-Westphalia`, sales_in_Saxony, `sales_in_Saxony-Anhalt`, `sales_in_Schleswig-Holstein`,
jj, url, plotti, Read_API, read_categories)
?glue
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
path <- "00_data/04_patent_data_short/"
glue("{path}patent_assignee.tsv")
glue("{path}patent_assignee.tsv", open = "\"")
glue("{path}patent_assignee.tsv", open = "\\"")
)
glue("{path}patent_assignee.tsv")
# Tidyverse
library(tidyverse)
library(vroom)
# Data Table
library(data.table)
# Counter
library(tictoc)
patent_assignee_col_types <- list(
patent_id = col_character(),
assignee_id = col_character(),
location_id = col_character()
)
path <- "00_data/04_patent_data_short/"
patent_assignee_tbl <- vroom(
file       = glue("{path}patent_assignee.tsv"),
delim      = "\t",
col_types = patent_assignee_col_types,
na         = c("", "NA", "NULL")
)
# Tidyverse
library(tidyverse)
library(vroom)
# Data Table
library(data.table)
# Counter
library(tictoc)
patent_assignee_col_types <- list(
patent_id = col_character(),
assignee_id = col_character()
)
path <- "00_data/04_patent_data_short/"
patent_assignee_tbl <- vroom(
file       = glue("{path}patent_assignee.tsv"),
delim      = "\t",
col_types = patent_assignee_col_types,
na         = c("", "NA", "NULL")
)
setDT(patent_assignee_tbl)
assignee_col_types <- list(
id = col_character(),
type = col_character(),
organization = col_character()
)
assignee_tbl <- vroom(
file       = "00_data/04_patent_data/assignee.tsv",
delim      = "\t",
col_types = assignee_col_types,
na         = c("", "NA", "NULL")
)
setDT(assignee_tbl)
patent_col_types <- list(
id = col_character(),
type = col_character(),
num_claims = col_double()
)
patent_tbl <- vroom(
file       = "00_data/04_patent_data/patent.tsv",
delim      = "\t",
col_types  = patent_col_types,
na         = c("", "NA", "NULL")
)
setDT(patent_tbl)
# Tidyverse
library(tidyverse)
library(vroom)
# Data Table
library(data.table)
# Counter
library(tictoc)
patent_assignee_col_types <- list(
patent_id = col_character(),
assignee_id = col_character()
)
path <- "00_data/04_patent_data_short/"
patent_assignee_tbl <- vroom(
file       = glue("{path}patent_assignee.tsv"),
delim      = "\t",
col_types = patent_assignee_col_types,
na         = c("", "NA", "NULL")
)
setDT(patent_assignee_tbl)
assignee_col_types <- list(
id = col_character(),
type = col_character(),
organization = col_character()
)
assignee_tbl <- vroom(
file       = glue("{path}assignee.tsv"),
delim      = "\t",
col_types = assignee_col_types,
na         = c("", "NA", "NULL")
)
setDT(assignee_tbl)
patent_col_types <- list(
id = col_character(),
type = col_character(),
num_claims = col_double()
)
patent_tbl <- vroom(
file       = glue("{path}patent.tsv"),
delim      = "\t",
col_types  = patent_col_types,
na         = c("", "NA", "NULL")
)
setDT(patent_tbl)
uspc_col_types <- list(
patent_id = col_character(),
mainclass_id = col_character(),
sequence = col_character()
)
uspc_tbl <- vroom(
file       = glue("{path}uspc.tsv"),
delim      = "\t",
col_types  = uspc_col_types,
na         = c("", "NA", "NULL")
)
setDT(uspc_tbl)
rm(patent_assignee_col_types, assignee_col_types, patent_col_types, uspc_col_types)
# merge patent_assignee_tbl and assignee_tbl
patent_dominance_tbl <- merge(x = patent_assignee_tbl, y = assignee_tbl,
by.x = "assignee_id",
by.y = "id",
all.x = TRUE,
all.y = FALSE)
# Filter after type = 2 (only US companies)
patent_dominance_US <- select(patent_dominance_tbl, organization, type, patent_id, assignee_id)[
type == 2 & !is.na(organization)]
# Count each patent for each organization
sorted_patent_dominance <- arrange(patent_dominance_US[, .N, by = organization],  desc(N))
slice(sorted_patent_dominance, c(1:10))
rm(sorted_patent_dominance)
rm(patent_assignee_col_types, assignee_col_types, patent_col_types, uspc_col_types, path)
View(patent_tbl)
# select only necessary columns of the patent table
patent_tbl <- select(patent_tbl, id, date)
# separate date into year | month | day
#select only id & year and filter after year = 2019
patent_tbl <- separate(patent_tbl,
col = date,
into = c("year", "month", "day"),
sep = "-", remove = FALSE)
# Sort by May
patent_tbl <- select(patent_tbl[month == 05], id, month)
patent_col_types <- list(
id = col_character(),
type = col_character(),
num_claims = col_double()
)
patent_tbl <- vroom(
file       = glue("{path}patent.tsv"),
delim      = "\t",
col_types  = patent_col_types,
na         = c("", "NA", "NULL")
)
path <- "00_data/04_patent_data_short/"
patent_col_types <- list(
id = col_character(),
type = col_character(),
num_claims = col_double()
)
patent_tbl <- vroom(
file       = glue("{path}patent.tsv"),
delim      = "\t",
col_types  = patent_col_types,
na         = c("", "NA", "NULL")
)
setDT(patent_tbl)
rm(patent_assignee_col_types, assignee_col_types, patent_col_types, uspc_col_types, path)
# select only necessary columns of the patent table
patent_tbl <- select(patent_tbl, id, date)
# separate date into year | month | day
#select only id & year and filter after month = 05 (May)
patent_tbl <- separate(patent_tbl,
col = date,
into = c("year", "month", "day"),
sep = "-", remove = FALSE)
patent_tbl[month == 05]
patent_tbl[month == 01]
patent_tbl[month == "01"]
select(patent_tbl[month == "05"], id, month)
view(select(patent_tbl[month == "05"], id, month))
# Sort by May
patent_tbl <- select(patent_tbl[month == "05"], id, month)
# merge patent_dominance with patents
patent_activity_tbl <- merge(x = patent_dominance_US, y = patent_tbl,
by.x = "patent_id",
by.y = "id",
all.x = TRUE,
all.y = FALSE)
# delete all patents that are not from 2019
sorted_patent_activity <- patent_activity_tbl[!is.na(year), .N, organization][order(-N)]
slice(sorted_patent_activity, c(1:10))
rm(patent_tbl, patent_activity_tbl, patent_assignee_tbl, patent_dominance_US, assignee_tbl)
uspc_tbl <- uspc_tbl[sequence == 0]
# select patent dominance worldwide
patent_dominance_worldwide <- select(patent_dominance_tbl[
type > 1 & type < 4 & !is.na(organization)], organization, patent_id)
# merge worldwide patent dominance table with uspc table
comb_tbl <- merge(x = patent_dominance_worldwide, y = uspc_tbl,
by = "patent_id",
all = FALSE)
comb_tbl <- select(comb_tbl, organization, patent_id, mainclass_id)
# Create List of top 10 worldwide patent owner
top_ten_tbl <- select(patent_dominance_tbl, organization, type, patent_id)[
type > 1 & type < 4 & !is.na(organization), .N, organization]
top_ten_tbl <- slice(top_ten_tbl[order(-N)], c(1:10))
# merge top 10 with comb_tbl to Filter out Organizations which are not in the Top 10
patent_innovation_tbl <- merge(x = comb_tbl, y = top_ten_tbl,
by = "organization",
all = FALSE)
# Count used Mainclass ID's
sorted_patent_innovation <- patent_innovation_tbl[, .N, mainclass_id][order(-N)]
slice(sorted_patent_innovation, c(1:10))
warnings()
